{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icu_experiments.load_data import load_data_for_prediction\n",
    "from icu_experiments.preprocessing import make_feature_preprocessing, make_anchor_preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor, Booster\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from ivmodels import AnchorRegression\n",
    "\n",
    "outcome = \"hr\"\n",
    "\n",
    "Xy = load_data_for_prediction([\"eicu\"], outcome=outcome, log_transform=True)\n",
    "Xy_train = Xy['eicu']['train']\n",
    "Xy_test = Xy['eicu']['test']\n",
    "\n",
    "Xy_new = load_data_for_prediction(['hirid'], outcome=outcome, log_transform=True)\n",
    "Xy_test_new = Xy_new['hirid']['train']\n",
    "Xy_tuning_data = Xy_new['hirid']['test']\n",
    "\n",
    "preprocessing_steps = make_feature_preprocessing(missing_indicator=True)\n",
    "preprocessor = ColumnTransformer(transformers=preprocessing_steps).set_output(transform=\"pandas\") # Allow to preprocess subbsets of data differently\n",
    "\n",
    "anchor_columns = ['hospital_id']\n",
    "anchor_preprocessing_steps = make_anchor_preprocessing(anchor_columns)\n",
    "anchor_preprocessor = ColumnTransformer(\n",
    "        anchor_preprocessing_steps + preprocessing_steps #preprocessing_steps\n",
    "    ).set_output(transform=\"pandas\")\n",
    "\n",
    "p1 = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', LGBMRegressor())\n",
    "])\n",
    "p2 = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', LGBMRegressor())\n",
    "])\n",
    "p3 = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "p4 = Pipeline(steps=[\n",
    "    ('preprocessing', anchor_preprocessor),\n",
    "    ('model', AnchorRegression())\n",
    "])\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'model__boosting_type': ['gbdt'], \n",
    "    'model__num_leaves': [15, 31],\n",
    "    'model__subsample': [0.8, 0.9],\n",
    "    'model__learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'model__n_estimators': [50, 100, 800]\n",
    "}\n",
    "param_grid_rf = {\n",
    "    'model__boosting_type': ['rf'],\n",
    "    'model__num_leaves': [15, 31],\n",
    "    'model__subsample': [0.8, 0.9],\n",
    "    'model__learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'model__n_estimators': [50, 100, 800]\n",
    "}\n",
    "param_grid_anchor = {\n",
    "    'instrument_regex': [\"anchor\"],\n",
    "    'gamma': [1, 3.16, 10, 31.6, 100, 316, 1000, 3162, 10000],\n",
    "    'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Performance from Training to Target Data - Parameters chosen via GridCV on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(p1, param_grid_lgbm)\n",
    "search.fit(Xy_train, Xy_train['outcome'])\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "grid_search_params_lgbm = search.best_params_\n",
    "print(search.best_params_)\n",
    "\n",
    "search = GridSearchCV(p2, param_grid_rf)\n",
    "search.fit(Xy_train, Xy_train['outcome'])\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "grid_search_params_rf = search.best_params_\n",
    "print(search.best_params_)\n",
    "\n",
    "p1.set_params(**grid_search_params_lgbm)\n",
    "p1.fit(Xy_train, Xy_train['outcome'])\n",
    "p2.set_params(**grid_search_params_rf)\n",
    "p2.fit(Xy_train, Xy_train['outcome'])\n",
    "\n",
    "mse_grid_lgbm = mean_squared_error(Xy_test_new['outcome'], p1.predict(Xy_test_new))\n",
    "mse_grid_rf = mean_squared_error(Xy_test_new['outcome'], p2.predict(Xy_test_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Performance from Training to Target Data - Parameters chosen via Evaluation on Target Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach: \n",
    "- Train Data with different parameters on Training set\n",
    "- Evaluate Train Data on fine tuning data from target set \n",
    "- choose the best performing parameters\n",
    "- do this for all possible n from the fine tuning data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_parameters(Xy_train, Xy_tuning_data, p, param_grid):\n",
    "    # Initialize a list to store the best parameters and MSE for each n\n",
    "    results_for_n = []\n",
    "\n",
    "    for n in [25, 50, 100, 200, 400, 800, 1600]:\n",
    "        # Initialize variables to keep track of the best parameters and MSE for the current n\n",
    "        best_params = None\n",
    "        best_mse = float('inf')  # Initialize with a large value\n",
    "\n",
    "        # Iterate over all possible combinations of hyperparameters\n",
    "        for param_set in itertools.product(*param_grid.values()):\n",
    "            param_dict = dict(zip(param_grid.keys(), param_set))\n",
    "\n",
    "            # Create and train the LightGBM model\n",
    "            params = {\n",
    "                **param_dict  # Include other relevant parameters\n",
    "            }\n",
    "            p.set_params(**{key: value for key, value in params.items()})\n",
    "            p.fit(Xy_train, Xy_train['outcome'])\n",
    "\n",
    "            # Make predictions on the subset of data\n",
    "            y_pred = p.predict(Xy_tuning_data.head(n))\n",
    "\n",
    "            # Calculate mean squared error for this parameter set\n",
    "            mse = mean_squared_error(Xy_tuning_data['outcome'].head(n), y_pred)\n",
    "\n",
    "            # Check if this MSE is better than the current best for the current n\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_params = param_dict\n",
    "\n",
    "        # Store the best parameters and MSE for the current n in the list\n",
    "        results_for_n.append({'n': n, 'best_params': best_params, 'best_mse': best_mse})\n",
    "\n",
    "    return results_for_n\n",
    "\n",
    "results_p1 = find_best_parameters(Xy_train, Xy_tuning_data, p1, param_grid_lgbm)\n",
    "results_p2 = find_best_parameters(Xy_train, Xy_tuning_data, p2, param_grid_rf)\n",
    "results_p4 = find_best_parameters(Xy_train, Xy_tuning_data, p4, param_grid_anchor)\n",
    "\n",
    "def calculate_mse(X_train, y_train, X_test, y_test, p, results, boosting_type=None, is_anchor=False):\n",
    "    mse_for_n = []\n",
    "    i = 0\n",
    "    for n in [25, 50, 100, 200, 400, 800, 1600]:\n",
    "        params = {f'model__{key}': value for key, value in results[i]['best_params'].items()}\n",
    "        if not is_anchor: \n",
    "            params['model__boosting_type'] = boosting_type\n",
    "        p.set_params(**params)\n",
    "        p.fit(X_train, y_train)\n",
    "        y_pred = p.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mse_for_n.append({'n': n, 'mse': mse})\n",
    "        i += 1\n",
    "    return mse_for_n\n",
    "\n",
    "mse_eicu_to_hirid_p1 = calculate_mse(Xy_train, Xy_train['outcome'], Xy_test_new, Xy_test_new['outcome'], p1, results_p1, 'gbdt')\n",
    "mse_eicu_to_hirid_p2 = calculate_mse(Xy_train, Xy_train['outcome'], Xy_test_new, Xy_test_new['outcome'], p2, results_p2, 'rf')\n",
    "mse_eicu_to_hirid_p4 = calculate_mse(Xy_train, Xy_train['outcome'], Xy_test_new, Xy_test_new['outcome'], p4, results_p4, is_anchor=True)\n",
    "\n",
    "# OLS MSE Calculation\n",
    "p3.fit(Xy_train, Xy_train['outcome'])\n",
    "mse_eicu_to_hirid_p3 = mean_squared_error(Xy_test_new['outcome'], p3.predict(Xy_test_new, Xy_test_new['outcome']))\n",
    "mse_eicu_to_hirid_dummy_prediction = mean_squared_error(Xy_test_new['outcome'], np.full_like(Xy_test_new['outcome'],Xy_train[outcome].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [25, 50, 100, 200, 400, 800, 1600]\n",
    "plt.plot(n, ([item['mse'] for item in mse_eicu_to_hirid_p1]), marker='o', linestyle='-', label = 'LGBM')\n",
    "plt.plot(n, [item['mse'] for item in mse_eicu_to_hirid_p2], marker='o', linestyle='-', label = 'RF')\n",
    "plt.plot(n, [item['mse'] for item in mse_eicu_to_hirid_p4], marker='o', linestyle='-', label = 'Anchor')\n",
    "plt.axhline(y=mse_eicu_to_hirid_p3, color='red', linestyle='-', label='OLS Baseline')\n",
    "plt.axhline(y=mse_grid_lgbm, color='green', linestyle='-', label='LGBM Baseline')\n",
    "plt.axhline(y=mse_grid_rf, color='purple', linestyle='-', label='RF Baseline')\n",
    "#plt.axhline(y = mean_squared_error(Xy_test_new['outcome'], np.full_like(Xy_test_new['outcome'],Xy_train[outcome].mean())), color = 'black', label='Train Average')\n",
    "plt.title('Parameters for Model chosen with evaluation on n Data Points from Target Distribution')\n",
    "plt.xlabel('Number of Data Points (n)')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "The hyperparameters were selected to minimize the Mean Squared Error (MSE) on the fine-tuning dataset of the target distribution. This fine-tuning dataset consists of various sizes, including n = 25, 50, 100, 200, 400, 800, and 1600 data points from the target distribution. Initially, we randomly selected 1600 data points from the target data and named it Xy_tuning_data, which is distinct from the final evaluation dataset used to generate the plotted MSE after model training, called Xy_test_new. \n",
    "\n",
    "The hyperparameters were chosen from three distinct parameter grids:\n",
    "```\n",
    "\n",
    "**LightGBM (param_grid_lgbm):**\n",
    "```python\n",
    "param_grid_lgbm = {\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'num_leaves': [15, 31],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],  \n",
    "    'n_estimators': [50, 100, 800]  \n",
    "}\n",
    "```\n",
    "\n",
    "**RF (param_grid_rf):**\n",
    "```python\n",
    "param_grid_rf = {\n",
    "    'boosting_type': ['rf'],\n",
    "    'num_leaves': [15, 31],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],  \n",
    "    'n_estimators': [50, 100, 800]  \n",
    "}\n",
    "```\n",
    "\n",
    "**Anchor (param_grid_anchor):**\n",
    "```python\n",
    "param_grid_anchor = {\n",
    "    'instrument_regex': [\"anchor\"],\n",
    "    'gamma': [1, 3.16, 10, 31.6, 100, 316, 1000, 3162, 10000],\n",
    "    'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "```\n",
    "\n",
    "**Evaluation Process:**\n",
    "```markdown\n",
    "Our evaluation process follows these steps:\n",
    "\n",
    "1. For each combination of the parameters, we train the model on the training data.\n",
    "2. Next, we calculate the MSE on the fine-tuning data from the training distribution.\n",
    "3. For each n value, we select the parameter combination that minimizes the MSE on the fine-tuning data.\n",
    "\n",
    "We have four distinct pipelines for our models:\n",
    "\n",
    "- LGBM pipeline: p1\n",
    "- Random Forest pipeline: p2\n",
    "- OLS pipeline: p3\n",
    "- Anchor pipeline: p4\n",
    "\n",
    "For OLS, we follow a slightly different approach. We train the model on the training data and evaluate it directly on the target data.\n",
    "\n",
    "In a subsequent step, we repeat the parameter selection process on the training data and calculate the MSE on the target data - we call this approach the Baseline. The plot displays the model's performance along with the Baseline.\n",
    "```\n",
    "\n",
    "**Model Performance:**\n",
    "```markdown\n",
    "Interestingly, none of the models managed to outperform the Baselines, except for LGBM with n = 1600, achieving the same level of precision. It appears that LGBM can identify crucial hyperparameters even with only 1600 tuning data points. After just 50 data points, Anchor outperforms OLS. Notably, the RF's predictive performance seems unaffected by the chosen parameters, while LGBM's performance is significantly influenced. With only 200 data points available, LGBM reduces its MSE by 8%.\n",
    "\n",
    "This observation could be attributed to the limited available hyperparameters. It would be intriguing to investigate whether the models can surpass their Baseline when provided with more possibilities. A potential follow-up question is whether predictive performance improves with n=2000 (Hypothesis: Yes, as the prediction benefits from more accurate data).\n",
    "\n",
    "Remarkably, all models outperformed the average prediction of the training data by a substantial margin (MSE = 283.59190335035487).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For p1/LGBM:**\n",
    "```markdown\n",
    "\n",
    "- n = 25\n",
    "  - best_params: {'boosting_type': 'gbdt', 'num_leaves': 15, 'subsample': 0.8, 'learning_rate': 0.2, 'n_estimators': 800}\n",
    "  - best_mse: 113.7853669744457\n",
    "\n",
    "- n = 50\n",
    "  - best_params: {'boosting_type': 'gbdt', 'num_leaves': 15, 'subsample': 0.8, 'learning_rate': 0.2, 'n_estimators': 800}\n",
    "  - best_mse: 151.03257816415527\n",
    "\n",
    "- n = 100\n",
    "  - best_params: {'boosting_type': 'gbdt', 'num_leaves': 15, 'subsample': 0.8, 'learning_rate': 0.2, 'n_estimators': 800}\n",
    "  - best_mse: 147.50302668110243\n",
    "\n",
    "- n = 200\n",
    "  - best_params: {'boosting_type': 'gbdt', 'num_leaves': 31, 'subsample': 0.8, 'learning_rate': 0.1, 'n_estimators': 100}\n",
    "  - best_mse: 159.93871260736046\n",
    "\n",
    "- n = 400\n",
    "  - best_params: {'boosting_type': 'gbdt', 'num_leaves': 31, 'subsample': 0.8, 'learning_rate': 0.1, 'n_estimators': 100}\n",
    "  - best_mse: 153.88405924738646\n",
    "\n",
    "- n = 800\n",
    "  - best_params: {'boosting_type': 'gbdt', 'num_leaves': 31, 'subsample': 0.8, 'learning_rate': 0.1, 'n_estimators': 100}\n",
    "  - best_mse: 148.97829215300928\n",
    "\n",
    "- n = 1600\n",
    "  - best_params: {'boosting_type': 'gbdt', 'num_leaves': 31, 'subsample': 0.8, 'learning_rate': 0.01, 'n_estimators': 800}\n",
    "  - best_mse: 163.99952271689486\n",
    "```\n",
    "**For p2/RF:**\n",
    "```markdown\n",
    "- n = 25\n",
    "  - best_params: {'boosting_type': 'rf', 'num_leaves': 15, 'subsample': 0.8, 'learning_rate': 0.001, 'n_estimators': 800}\n",
    "  - best_mse: 140.62296079918235\n",
    "\n",
    "- n = 50\n",
    "  - best_params: {'boosting_type': 'rf', 'num_leaves': 15, 'subsample': 0.8, 'learning_rate': 0.001, 'n_estimators': 800}\n",
    "  - best_mse: 169.23772353266452\n",
    "\n",
    "- n = 100\n",
    "  - best_params: {'boosting_type': 'rf', 'num_leaves': 15, 'subsample': 0.8, 'learning_rate': 0.001, 'n_estimators': 800}\n",
    "  - best_mse: 156.54175652388255\n",
    "\n",
    "- n = 200\n",
    "  - best_params: {'boosting_type': 'rf', 'num_leaves': 15, 'subsample': 0.8, 'learning_rate': 0.001, 'n_estimators': 800}\n",
    "  - best_mse: 170.28568523948127\n",
    "\n",
    "- n = 400\n",
    "  - best_params: {'boosting_type': 'rf', 'num_leaves': 15, 'subsample': 0.8, 'learning_rate': 0.001, 'n_estimators': 800}\n",
    "  - best_mse: 159.52549273668203\n",
    "\n",
    "- n = 800\n",
    "  - best_params: {'boosting_type': 'rf', 'num_leaves': 15, 'subsample': 0.8, 'learning_rate': 0.001, 'n_estimators': 800}\n",
    "  - best_mse: 154.98743617760542\n",
    "\n",
    "- n = 1600\n",
    "  - best_params: {'boosting_type': 'rf', 'num_leaves': 15, 'subsample': 0.8, 'learning_rate': 0.001, 'n_estimators': 800}\n",
    "  - best_mse: 171.13541258639327\n",
    "\n",
    "```\n",
    "**For p3/OLS:**\n",
    "```markdown\n",
    "- OLS:\n",
    "  - Test Error: 159.65984526272683\n",
    "```\n",
    "\n",
    "**For p4/Anchor:**\n",
    "```markdown\n",
    "- n = 25\n",
    "  - best_params: {'instrument_regex': 'anchor', 'gamma': 1, 'alpha': 0.1}\n",
    "  - best_mse: 145.0284017501739\n",
    "\n",
    "- n = 50\n",
    "  - best_params: {'instrument_regex': 'anchor', 'gamma': 1, 'alpha': 0.001}\n",
    "  - best_mse: 166.65092062151024\n",
    "\n",
    "- n = 100\n",
    "  - best_params: {'instrument_regex': 'anchor', 'gamma': 3.16, 'alpha': 0.01}\n",
    "  - best_mse: 152.59928450652117\n",
    "\n",
    "- n = 200\n",
    "  - best_params: {'instrument_regex': 'anchor', 'gamma': 1, 'alpha': 1e-05}\n",
    "  - best_mse: 165.26237755409892\n",
    "\n",
    "- n = 400\n",
    "  - best_params: {'instrument_regex': 'anchor', 'gamma': 1, 'alpha': 1e-05}\n",
    "  - best_mse: 155.53044386121334\n",
    "\n",
    "- n = 800\n",
    "  - best_params: {'instrument_regex': 'anchor', 'gamma': 1, 'alpha': 1e-05}\n",
    "  - best_mse: 151.55849601840572\n",
    "\n",
    "- n = 1600\n",
    "  - best_params: {'instrument_regex': 'anchor', 'gamma': 1, 'alpha': 0.01}\n",
    "  - best_mse: 165.51230906082435\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For p1/LGBM:**\n",
    "```markdown\n",
    "- n = 25, mse = 172.77225379649616\n",
    "- n = 50, mse = 172.77225379649616\n",
    "- n = 100, mse = 172.77225379649616\n",
    "- n = 200, mse = 158.45334348900073\n",
    "- n = 400, mse = 158.45334348900073\n",
    "- n = 800, mse = 158.45334348900073\n",
    "- n = 1600, mse = 157.66217932606298\n",
    "```\n",
    "**For p2/RF:**\n",
    "```markdown\n",
    "- n = 25, mse = 163.39728426435462\n",
    "- n = 50, mse = 163.39728426435462\n",
    "- n = 100, mse = 163.39728426435462\n",
    "- n = 200, mse = 163.39728426435462\n",
    "- n = 400, mse = 163.39728426435462\n",
    "- n = 800, mse = 163.39728426435462\n",
    "- n = 1600, mse = 163.39728426435462\n",
    "```\n",
    "**For p2/RF:**\n",
    "```markdown\n",
    "- n = 25, mse = 159.97760862179274\n",
    "- n = 50, mse = 159.47863383193007\n",
    "- n = 100, mse = 158.96353854009493\n",
    "- n = 200, mse = 159.6254589611603\n",
    "- n = 400, mse = 159.6254589611603\n",
    "- n = 800, mse = 159.6254589611603\n",
    "- n = 1600, mse = 158.93096747576763\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for the baseline models are as follows:\n",
    "\n",
    "**LGBM Baseline (CV score=0.430):**\n",
    "- `boosting_type`: 'gbdt'\n",
    "- `learning_rate`: 0.01\n",
    "- `n_estimators`: 800\n",
    "- `num_leaves`: 31\n",
    "- `subsample`: 0.8\n",
    "\n",
    "**RF Baseline (CV score=0.408):**\n",
    "- `boosting_type`: 'rf'\n",
    "- `learning_rate`: 0.001\n",
    "- `n_estimators`: 800\n",
    "- `num_leaves`: 31\n",
    "- `subsample`: 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgbm = {\n",
    "    'model__boosting_type': ['gbdt'],  # Set the boosting type for LightGBM\n",
    "    'model__subsample': [0.6, 0.8, 1.0],\n",
    "    'model__learning_rate': [0.001, 0.01, 0.05 0.1, 0.2, 0.3],\n",
    "    'model__n_estimators': [50, 100, 800, 3000]\n",
    "}\n",
    "param_grid_rf = {\n",
    "    'model__boosting_type': ['rf'],  # Set the boosting type for LightGBM\n",
    "    'model__subsample': [0.6, 0.8, 1.0],\n",
    "    'model__learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'model__n_estimators': [50, 100, 800, 3000]\n",
    "}\n",
    "\n",
    "results_p1_new = find_best_parameters(Xy_train, Xy_tuning_data, p1, param_grid_lgbm)\n",
    "results_p2_new = find_best_parameters(Xy_train, Xy_tuning_data, p2, param_grid_rf)\n",
    "\n",
    "mse_eicu_to_hirid_p1_new = calculate_mse(Xy_train, Xy_train['outcome'], Xy_test_new, Xy_test_new['outcome'], p1, results_p1_new, 'gbdt')\n",
    "mse_eicu_to_hirid_p2_new = calculate_mse(Xy_train, Xy_train['outcome'], Xy_test_new, Xy_test_new['outcome'], p2, results_p2_new, 'rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lack of Predictive Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, there is no significant predictive improvement observed when allowing more parameters in the selection process. The mean squared errors (MSE) for different values of 'n' remain relatively consistent for the following models:\n",
    "\n",
    "**For p1 / LGBM:**\n",
    "- n = 25, MSE = 172.77\n",
    "- n = 50, MSE = 172.77\n",
    "- n = 100, MSE = 172.77\n",
    "- n = 200, MSE = 158.45\n",
    "- n = 400, MSE = 158.45\n",
    "- n = 800, MSE = 158.45\n",
    "- n = 1600, MSE = 157.66\n",
    "\n",
    "**For p2 / RF:**\n",
    "- n = 25, MSE = 163.40\n",
    "- n = 50, MSE = 163.40\n",
    "- n = 100, MSE = 163.40\n",
    "- n = 200, MSE = 163.40\n",
    "- n = 400, MSE = 163.40\n",
    "- n = 800, MSE = 163.40\n",
    "- n = 1600, MSE = 163.40\n",
    "\n",
    "These results indicate that increasing the number of parameters did not lead to a significant reduction in MSE for both LGBM and RF models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Malte Fragen beantworten: \n",
    "    - Sowohl RF wie LGBM mit tuning auf target distr. data sind schlechter (nie besser) als die Baselines, egal wie gross “n” ist. Wieso?\n",
    "    - Dein MSE der OLS baseline eICU -> MIMIC III ist signifikant besser als das was ich in dem pdf das ich dir mal geschickt hatte habe (~175). Was machst du anders?\n",
    "- Andere Target Distr. anschauen\n",
    "- Refit implementieren und anschauen\n",
    "- Customized Anchor implementieren"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataICU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
